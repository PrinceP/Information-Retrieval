{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import six.moves.cPickle as pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import gzip\n",
    "import os\n",
    "import urllib\n",
    "import random\n",
    "import stat\n",
    "import subprocess\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "# Otherwise the deepcopy fails\n",
    "import sys\n",
    "sys.setrecursionlimit(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREFIX = os.getenv('ATISDATA',os.path.join(os.path.split(os.path.abspath(os.path.dirname('__file__')))[0],'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def shuffle(lol, seed):\n",
    "    '''\n",
    "    lol :: list of list as input\n",
    "    seed :: seed the shuffling\n",
    "\n",
    "    shuffle inplace each list in the same order\n",
    "    '''\n",
    "    for l in lol:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start-snippet-1\n",
    "def contextwin(l, win):\n",
    "    '''\n",
    "    win :: int corresponding to the size of the window\n",
    "    given a list of indexes composing a sentence\n",
    "\n",
    "    l :: array containing the word indexes\n",
    "\n",
    "    it will return a list of list of indexes corresponding\n",
    "    to context windows surrounding each word in the sentence\n",
    "    '''\n",
    "    assert (win % 2) == 1\n",
    "    assert win >= 1\n",
    "    l = list(l)\n",
    "\n",
    "    lpadded = win // 2 * [-1] + l + win // 2 * [-1]\n",
    "    out = [lpadded[i:(i + win)] for i in range(len(l))]\n",
    "\n",
    "    assert len(out) == len(l)\n",
    "    return out\n",
    "# end-snippet-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# data loading functions\n",
    "def atisfold(fold):\n",
    "    assert fold in range(5)\n",
    "    filename = os.path.join(PREFIX, 'atis.fold'+str(fold)+'.pkl.gz')\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    try:\n",
    "        train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set, dicts = pickle.load(f)\n",
    "    return train_set, valid_set, test_set, dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics function using conlleval.pl\n",
    "def conlleval(p, g, w, filename, script_path):\n",
    "    '''\n",
    "    INPUT:\n",
    "    p :: predictions\n",
    "    g :: groundtruth\n",
    "    w :: corresponding words\n",
    "\n",
    "    OUTPUT:\n",
    "    filename :: name of the file where the predictions\n",
    "    are written. it will be the input of conlleval.pl script\n",
    "    for computing the performance in terms of precision\n",
    "    recall and f1 score\n",
    "\n",
    "    OTHER:\n",
    "    script_path :: path to the directory containing the\n",
    "    conlleval.pl script\n",
    "    '''\n",
    "    out = ''\n",
    "    for sl, sp, sw in zip(g, p, w):\n",
    "        out += 'BOS O O\\n'\n",
    "        for wl, wp, w in zip(sl, sp, sw):\n",
    "            out += w + ' ' + wl + ' ' + wp + '\\n'\n",
    "        out += 'EOS O O\\n\\n'\n",
    "\n",
    "    f = open(filename, 'w')\n",
    "    f.writelines(out)\n",
    "    f.close()\n",
    "\n",
    "    return get_perf(filename, script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(origin, destination):\n",
    "    '''\n",
    "    download the corresponding atis file\n",
    "    from http://www-etud.iro.umontreal.ca/~mesnilgr/atis/\n",
    "    '''\n",
    "    print('Downloading data from %s' % origin)\n",
    "    urllib.urlretrieve(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_perf(filename, folder):\n",
    "    ''' run conlleval.pl perl script to obtain\n",
    "    precision/recall and F1 score '''\n",
    "    _conlleval = os.path.join(folder, 'conlleval.pl')\n",
    "    if not os.path.isfile(_conlleval):\n",
    "        url = 'http://www-etud.iro.umontreal.ca/~mesnilgr/atis/conlleval.pl'\n",
    "        download(url, _conlleval)\n",
    "        os.chmod(_conlleval, stat.S_IRWXU)  # give the execute permissions\n",
    "\n",
    "    proc = subprocess.Popen([\"perl\",\n",
    "                            _conlleval],\n",
    "                            stdin=subprocess.PIPE,\n",
    "                            stdout=subprocess.PIPE)\n",
    "\n",
    "    stdout, _ = proc.communicate(''.join(open(filename).readlines()).encode('utf-8'))\n",
    "    stdout = stdout.decode('utf-8')\n",
    "    out = None\n",
    "\n",
    "    for line in stdout.split('\\n'):\n",
    "        if 'accuracy' in line:\n",
    "            out = line.split()\n",
    "            break\n",
    "    # To help debug\n",
    "    if out is None:\n",
    "        print(stdout.split('\\n'))\n",
    "    precision = float(out[6][:-2])\n",
    "    recall = float(out[8][:-2])\n",
    "    f1score = float(out[10])\n",
    "\n",
    "    return {'p': precision, 'r': recall, 'f1': f1score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start-snippet-2\n",
    "class RNNSLU(object):\n",
    "    ''' elman neural net model '''\n",
    "    def __init__(self, nh, nc, ne, de, cs):\n",
    "        '''\n",
    "        nh :: dimension of the hidden layer\n",
    "        nc :: number of classes\n",
    "        ne :: number of word embeddings in the vocabulary\n",
    "        de :: dimension of the word embeddings\n",
    "        cs :: word window context size\n",
    "        '''\n",
    "        # parameters of the model\n",
    "        self.emb = theano.shared(name='embeddings',\n",
    "                                 value=0.2 * numpy.random.uniform(-1.0, 1.0,\n",
    "                                 (ne+1, de))\n",
    "                                 # add one for padding at the end\n",
    "                                 .astype(theano.config.floatX))\n",
    "        self.wx = theano.shared(name='wx',\n",
    "                                value=0.2 * numpy.random.uniform(-1.0, 1.0,\n",
    "                                (de * cs, nh))\n",
    "                                .astype(theano.config.floatX))\n",
    "        self.wh = theano.shared(name='wh',\n",
    "                                value=0.2 * numpy.random.uniform(-1.0, 1.0,\n",
    "                                (nh, nh))\n",
    "                                .astype(theano.config.floatX))\n",
    "        self.w = theano.shared(name='w',\n",
    "                               value=0.2 * numpy.random.uniform(-1.0, 1.0,\n",
    "                               (nh, nc))\n",
    "                               .astype(theano.config.floatX))\n",
    "        self.bh = theano.shared(name='bh',\n",
    "                                value=numpy.zeros(nh,\n",
    "                                dtype=theano.config.floatX))\n",
    "        self.b = theano.shared(name='b',\n",
    "                               value=numpy.zeros(nc,\n",
    "                               dtype=theano.config.floatX))\n",
    "        self.h0 = theano.shared(name='h0',\n",
    "                                value=numpy.zeros(nh,\n",
    "                                dtype=theano.config.floatX))\n",
    "\n",
    "        # bundle\n",
    "        self.params = [self.emb, self.wx, self.wh, self.w,\n",
    "                       self.bh, self.b, self.h0]\n",
    "        # end-snippet-2\n",
    "        # as many columns as context window size\n",
    "        # as many lines as words in the sentence\n",
    "        # start-snippet-3\n",
    "        idxs = T.imatrix()\n",
    "        x = self.emb[idxs].reshape((idxs.shape[0], de*cs))\n",
    "        y_sentence = T.ivector('y_sentence')  # labels\n",
    "        # end-snippet-3 start-snippet-4\n",
    "\n",
    "        def recurrence(x_t, h_tm1):\n",
    "            h_t = T.nnet.sigmoid(T.dot(x_t, self.wx)\n",
    "                                 + T.dot(h_tm1, self.wh) + self.bh)\n",
    "            s_t = T.nnet.softmax(T.dot(h_t, self.w) + self.b)\n",
    "            return [h_t, s_t]\n",
    "\n",
    "        [h, s], _ = theano.scan(fn=recurrence,\n",
    "                                sequences=x,\n",
    "                                outputs_info=[self.h0, None],\n",
    "                                n_steps=x.shape[0])\n",
    "\n",
    "        p_y_given_x_sentence = s[:, 0, :]\n",
    "        y_pred = T.argmax(p_y_given_x_sentence, axis=1)\n",
    "        # end-snippet-4\n",
    "\n",
    "        # cost and gradients and learning rate\n",
    "        # start-snippet-5\n",
    "        lr = T.scalar('lr')\n",
    "\n",
    "        sentence_nll = -T.mean(T.log(p_y_given_x_sentence)\n",
    "                               [T.arange(x.shape[0]), y_sentence])\n",
    "        sentence_gradients = T.grad(sentence_nll, self.params)\n",
    "        sentence_updates = OrderedDict((p, p - lr*g)\n",
    "                                       for p, g in\n",
    "                                       zip(self.params, sentence_gradients))\n",
    "        # end-snippet-5\n",
    "\n",
    "        # theano functions to compile\n",
    "        # start-snippet-6\n",
    "        self.classify = theano.function(inputs=[idxs], outputs=y_pred)\n",
    "        self.sentence_train = theano.function(inputs=[idxs, y_sentence, lr],\n",
    "                                              outputs=sentence_nll,\n",
    "                                              updates=sentence_updates)\n",
    "        # end-snippet-6 start-snippet-7\n",
    "        self.normalize = theano.function(inputs=[],\n",
    "                                         updates={self.emb:\n",
    "                                                  self.emb /\n",
    "                                                  T.sqrt((self.emb**2)\n",
    "                                                  .sum(axis=1))\n",
    "                                                  .dimshuffle(0, 'x')})\n",
    "        # end-snippet-7\n",
    "\n",
    "    def train(self, x, y, window_size, learning_rate):\n",
    "\n",
    "        cwords = contextwin(x, window_size)\n",
    "        words = list(map(lambda x: numpy.asarray(x).astype('int32'), cwords))\n",
    "        labels = y\n",
    "\n",
    "        self.sentence_train(words, labels, learning_rate)\n",
    "        self.normalize()\n",
    "\n",
    "    def save(self, folder):\n",
    "        for param in self.params:\n",
    "            numpy.save(os.path.join(folder,\n",
    "                       param.name + '.npy'), param.get_value())\n",
    "\n",
    "    def load(self, folder):\n",
    "        for param in self.params:\n",
    "            param.set_value(numpy.load(os.path.join(folder,\n",
    "                            param.name + '.npy')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(param=None):\n",
    "    if not param:\n",
    "        param = {\n",
    "            'fold': 3,\n",
    "            # 5 folds 0,1,2,3,4\n",
    "            'data': 'atis',\n",
    "            'lr': 0.0970806646812754,\n",
    "            'verbose': 1,\n",
    "            'decay': True,\n",
    "            # decay on the learning rate if improvement stops\n",
    "            'win': 7,\n",
    "            # number of words in the context window\n",
    "            'nhidden': 200,\n",
    "            # number of hidden units\n",
    "            'seed': 345,\n",
    "            'emb_dimension': 50,\n",
    "            # dimension of word embedding\n",
    "            'nepochs': 60,\n",
    "            # 60 is recommended\n",
    "            'savemodel': False}\n",
    "    print(param)\n",
    "\n",
    "    folder_name = os.path.basename('__file__').split('.')[0]\n",
    "    folder = os.path.join(os.path.dirname('__file__'), folder_name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    # load the dataset\n",
    "    train_set, valid_set, test_set, dic = atisfold(param['fold'])\n",
    "\n",
    "    idx2label = dict((k, v) for v, k in dic['labels2idx'].items())\n",
    "    idx2word = dict((k, v) for v, k in dic['words2idx'].items())\n",
    "\n",
    "    train_lex, train_ne, train_y = train_set\n",
    "    valid_lex, valid_ne, valid_y = valid_set\n",
    "    test_lex, test_ne, test_y = test_set\n",
    "\n",
    "    vocsize = len(dic['words2idx'])\n",
    "    nclasses = len(dic['labels2idx'])\n",
    "    nsentences = len(train_lex)\n",
    "\n",
    "    groundtruth_valid = [map(lambda x: idx2label[x], y) for y in valid_y]\n",
    "    words_valid = [map(lambda x: idx2word[x], w) for w in valid_lex]\n",
    "    groundtruth_test = [map(lambda x: idx2label[x], y) for y in test_y]\n",
    "    words_test = [map(lambda x: idx2word[x], w) for w in test_lex]\n",
    "\n",
    "    # instanciate the model\n",
    "    numpy.random.seed(param['seed'])\n",
    "    random.seed(param['seed'])\n",
    "\n",
    "    rnn = RNNSLU(nh=param['nhidden'],\n",
    "                 nc=nclasses,\n",
    "                 ne=vocsize,\n",
    "                 de=param['emb_dimension'],\n",
    "                 cs=param['win'])\n",
    "\n",
    "    # train with early stopping on validation set\n",
    "    best_f1 = -numpy.inf\n",
    "    param['clr'] = param['lr']\n",
    "    for e in range(param['nepochs']):\n",
    "\n",
    "        # shuffle\n",
    "        shuffle([train_lex, train_ne, train_y], param['seed'])\n",
    "\n",
    "        param['ce'] = e\n",
    "        tic = timeit.default_timer()\n",
    "\n",
    "        for i, (x, y) in enumerate(zip(train_lex, train_y)):\n",
    "            rnn.train(x, y, param['win'], param['clr'])\n",
    "            print('[learning] epoch %i >> %2.2f%%' % (\n",
    "                e, (i + 1) * 100. / nsentences), end=' ')\n",
    "            print('completed in %.2f (sec) <<\\r' % (timeit.default_timer() - tic), end='')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # evaluation // back into the real world : idx -> words\n",
    "        predictions_test = [map(lambda x: idx2label[x],\n",
    "                            rnn.classify(numpy.asarray(\n",
    "                            contextwin(x, param['win'])).astype('int32')))\n",
    "                            for x in test_lex]\n",
    "        predictions_valid = [map(lambda x: idx2label[x],\n",
    "                             rnn.classify(numpy.asarray(\n",
    "                             contextwin(x, param['win'])).astype('int32')))\n",
    "                             for x in valid_lex]\n",
    "\n",
    "        # evaluation // compute the accuracy using conlleval.pl\n",
    "        res_test = conlleval(predictions_test,\n",
    "                             groundtruth_test,\n",
    "                             words_test,\n",
    "                             folder + '/current.test.txt',\n",
    "                             folder)\n",
    "        res_valid = conlleval(predictions_valid,\n",
    "                              groundtruth_valid,\n",
    "                              words_valid,\n",
    "                              folder + '/current.valid.txt',\n",
    "                              folder)\n",
    "\n",
    "        if res_valid['f1'] > best_f1:\n",
    "\n",
    "            if param['savemodel']:\n",
    "                rnn.save(folder)\n",
    "\n",
    "            best_rnn = copy.deepcopy(rnn)\n",
    "            best_f1 = res_valid['f1']\n",
    "\n",
    "            if param['verbose']:\n",
    "                print('NEW BEST: epoch', e,\n",
    "                      'valid F1', res_valid['f1'],\n",
    "                      'best test F1', res_test['f1'])\n",
    "\n",
    "            param['vf1'], param['tf1'] = res_valid['f1'], res_test['f1']\n",
    "            param['vp'], param['tp'] = res_valid['p'], res_test['p']\n",
    "            param['vr'], param['tr'] = res_valid['r'], res_test['r']\n",
    "            param['be'] = e\n",
    "\n",
    "            subprocess.call(['mv', folder + '/current.test.txt',\n",
    "                            folder + '/best.test.txt'])\n",
    "            subprocess.call(['mv', folder + '/current.valid.txt',\n",
    "                            folder + '/best.valid.txt'])\n",
    "        else:\n",
    "            if param['verbose']:\n",
    "                print('')\n",
    "\n",
    "        # learning rate decay if no improvement in 10 epochs\n",
    "        if param['decay'] and abs(param['be']-param['ce']) >= 10:\n",
    "            param['clr'] *= 0.5\n",
    "            rnn = best_rnn\n",
    "\n",
    "        if param['clr'] < 1e-5:\n",
    "            break\n",
    "\n",
    "    print('BEST RESULT: epoch', param['be'],\n",
    "           'valid F1', param['vf1'],\n",
    "           'best test F1', param['tf1'],\n",
    "           'with the model', folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
